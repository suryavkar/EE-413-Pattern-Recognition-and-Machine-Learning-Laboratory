{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SxibeRm0eHP"
   },
   "source": [
    "##***LAB 10 : Naive Bayes Classifier***##\n",
    "\n",
    "  1. Binary Classification using Naive Bayes Classifier\n",
    "  \n",
    "  2. Sentiment Analysis using Naive Bayes\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JL_2f9KRjax4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='gruvboxd',context='notebook',grid=False,ticks=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kFmTcwYjaLM"
   },
   "source": [
    "##Binary Classification using Naive Bayes Classifier##\n",
    "\n",
    "Useful References : \n",
    "1. https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/\n",
    "\n",
    "2. https://www.analyticsvidhya.com/blog/2021/01/a-guide-to-the-naive-bayes-algorithm/\n",
    "\n",
    "3. https://towardsdatascience.com/implementing-naive-bayes-algorithm-from-scratch-python-c6880cfc9c41\n",
    "\n",
    "**Note : The goal of this experiment is to perform and understand Naive Bayes classification by applying it on the below dataset, you can either fill in the below functions to get the result or you can create a class of your own using the above references to perform classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buED4mnvjz_5"
   },
   "source": [
    "1. Generation of 2D training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "pXA9oMypj3OM",
    "outputId": "7907c6e3-b106-4492-e35f-26a1f03e5a63"
   },
   "outputs": [],
   "source": [
    "mean1=np.array([0,0])\n",
    "mean2=np.array([4,5])\n",
    "var=np.array([[1,0.1],[0.1,1]])\n",
    "np.random.seed(0)\n",
    "data1=np.random.multivariate_normal(mean1,var,50)\n",
    "data2=np.random.multivariate_normal(mean2,var,50)\n",
    "data=np.concatenate((data1,data2))\n",
    "label=np.concatenate((np.zeros(data1.shape[0]),np.ones(data2.shape[0])))\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(data[:,0],data[:,1],c=label)\n",
    "plt.title('Data visualization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6cJBcLjTpMpX"
   },
   "source": [
    "2. Split the Dataset by Class Values (Create a Dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vYfrEmkJn8I7",
    "outputId": "aac75912-f557-45a1-e709-08b3e367415c"
   },
   "outputs": [],
   "source": [
    "def class_dictionary(data,label):\n",
    "  class_dict = {}\n",
    "\n",
    "  ## Write your code here\n",
    "\n",
    "  return class_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2FlXCa5q2rt"
   },
   "source": [
    "3. Calculate Mean, Std deviation and count for each column in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vhy2NkxQq8EO",
    "outputId": "70e1e354-c534-41db-a23a-530f84dcf182"
   },
   "outputs": [],
   "source": [
    "def get_variables(class_dict):\n",
    "  var_dict = {}\n",
    "\n",
    "  ## Write your code here\n",
    "\n",
    "  return var_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKFDa--0sqlR"
   },
   "source": [
    "3. Calculate Class Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_cEkA46bsteW"
   },
   "outputs": [],
   "source": [
    "def calculate_probability(x,mean,stdev):\n",
    "  exponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "  return (1 / (sqrt(2 * pi) * stdev)) * exponent\n",
    "\n",
    "def calculate_class_probabilities(summaries,row):\n",
    "  probabilities = dict()\n",
    "\n",
    "  ## Write your code here to calculate the class probabilities\n",
    "  '''\n",
    "  You can use the above function (calculate_probability) to calculate probability of an individual data point belonging to a particular class \n",
    "  based on mean and std deviation of that class\n",
    "  \n",
    "  '''\n",
    "  return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14kbEgqEw9_a"
   },
   "source": [
    "4. Test the model using some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "x2TpLdVWw9CS",
    "outputId": "b0757acf-9cfd-4cd8-a767-233eb9408252"
   },
   "outputs": [],
   "source": [
    "## Test Data Generation\n",
    "\n",
    "mean1=np.array([0,0])\n",
    "mean2=np.array([4,5])\n",
    "var=np.array([[1,0.1],[0.1,1]])\n",
    "np.random.seed(0)\n",
    "data1=np.random.multivariate_normal(mean1,var,10)\n",
    "data2=np.random.multivariate_normal(mean2,var,10)\n",
    "test_data=np.concatenate((data1,data2))\n",
    "y_test=np.concatenate((np.zeros(data1.shape[0]),np.ones(data2.shape[0])))\n",
    "print('Test Data Size : ',test_data.shape[0])\n",
    "plt.figure()\n",
    "plt.scatter(data[:,0],data[:,1],c=label)\n",
    "plt.title('Data visualization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLbY6KhzzoHw"
   },
   "source": [
    "Testing for a sample point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cVcXm0UCxTcQ",
    "outputId": "f1a66200-ad53-4b8b-f09c-8b1f69ef05ed"
   },
   "outputs": [],
   "source": [
    "class_dict = class_dictionary(data,label)\n",
    "var_dict = get_variables(class_dict)\n",
    "out = calculate_class_probabilities(var_dict,test_data[0])\n",
    "print('Class Probabilites for the first sample of test dataset : ')\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjV6DO0myhKQ"
   },
   "source": [
    "**As seen above the class probability for the 1st sample is given, we can observe that probability is higher for class 0 than 1 and hence imply that this datapoint belongs to class 0**\n",
    "\n",
    "\n",
    "Now Calculate the class probabilities for all the data points in the test dataset and calculate the accuracy by comparing the predicted labels with the true test labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rs-UXbl2y-2N"
   },
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qc_SfqHkz3Kz"
   },
   "source": [
    "5. Use the Sci-kit Learn library to perform Gaussian Naive Bayes classifier on the above dataset, also report the accuracy and confusion matrix for the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vt0veSsf0BVV"
   },
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UTNODz-zsf1"
   },
   "source": [
    "##Sentiment Analysis using Naive Bayes Classifier##\n",
    "\n",
    "Go through the following [article](https://www.analyticsvidhya.com/blog/2021/07/performing-sentiment-analysis-with-naive-bayes-classifier/) and implement the same \n",
    "\n",
    "**Keypoints** : \n",
    "  \n",
    "  1. The link to the dataset is given in the above article, download the same to perform sentiment analysis\n",
    "\n",
    "  2. Understanding how to deal with text data is very important since it requires a lot of preprocessing, you can go through this [article](https://www.analyticsvidhya.com/blog/2021/06/text-preprocessing-in-nlp-with-python-codes/) if you are interested in learning more about it\n",
    "  \n",
    "  3. Split the dataset into train-test and train the model\n",
    "  \n",
    "  4. Report the accuracy metrics and try some sample prediction outside of those present in the dataset\n",
    "\n",
    "\n",
    "**Note : The goal of this experiment is to explore a practical use case of Naive bayes classifier as well as to understand how to deal with textual data, you can follow any other open source implemetations of sentiment analysis using naive bayes also**\n",
    "\n",
    "Other References : \n",
    "\n",
    "1. https://towardsdatascience.com/sentiment-analysis-introduction-to-naive-bayes-algorithm-96831d77ac91\n",
    "\n",
    "2. https://gist.github.com/CateGitau/6608912ca92733036c090676c61c13cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5x6A4Mp4zw0E"
   },
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab_10_Naive_Bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
